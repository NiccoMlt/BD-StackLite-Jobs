%% Direttive TeXworks:
% !TeX root = ../report.tex
% !TEX encoding = UTF-8 Unicode
% !TeX spellcheck = it-IT

% arara: pdflatex: { synctex: yes, shell: yes, interaction: nonstopmode }
% arara: pdflatex: { synctex: yes, shell: yes, interaction: nonstopmode }

\subsection{Job 1: Proporzione giorni feriali/festivi per tag}\label{subsec:job1}
  Il primo job concordato consiste nel calcolo, per ciascun tag, della proporzione tra la quantità di post che lo utilizzano creati in giorni feriali e giorni festivi, tenendo traccia della quantità totale ai fini dell'ordinamento.

  Durante la fase di studio del dataset, è risultato subito evidente l'esigenza di utilizzare entrambi i file,
  effettuando un \textit{join} per ID della domanda in modo da poter mettere in relazioni i singoli tag con le informazioni relative ai giorni di apparizione;
  il passo logico successivo è il raggruppamento per tag ai fini del calcolo del numero di apparizioni e della proporzione.

  Si è inoltre ritenuto non necessario mantenere la data di creazione come stringa nella pipeline, in quanto più che sufficiente un booleano che modellasse la festività o meno del giorno di creazione;
  per verificare se un giorno è festivo o meno si è deciso di appoggiarsi alla libreria \textit{Jollyday}\footnote{\url{http://jollyday.sourceforge.net/}} utilizzando il calendario italiano come riferimento per le festività.

  \subsubsection{MapReduce implementation}\label{subsub:job1:mapreduce}

  \paragraph{Comando per eseguire il Job}\label{par:job1:mapreduce:cmd}

  \texttt{hadoop jar bd-stacklite-jobs-1.0.0-mr1.jar}

  Essendo la classe \textit{main} eseguita tramite \texttt{ToolRunner} di Hadoop,
  supporta il parsing di parametri standard di Hadoop\footnote{\url{https://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-common/CommandsManual.html}}, quali ad esempio:
  \begin{itemize}
    \item \texttt{-conf} per caricare una configurazione esterna;
    \item \texttt{-D} per specificare proprietà specifiche per la configurazione;
    \item \texttt{-h} o \texttt{--help} per stampare le opzioni accettate.
  \end{itemize}

  Inoltre, è possibile specificare come primo parametro il path della cartella in ingresso e come secondo paramtero quello della cartella in uscita.

  \paragraph{Link all'esecuzione su YARN}\label{par:job1:mapreduce:yarn}

  \textbf{TODO}

  \paragraph{File/Tabelle di Input}\label{par:job1:mapreduce:input}

  Le colonne necessarie al raggiungimento dell'obiettivo dell'analisi sono \texttt{Id} e \texttt{CreationDate} per il file \texttt{questions.csv}
  e \texttt{Id} e \texttt{Tag} per \texttt{question\_tags.csv}.

  Se non si effettua override dei percorsi tramite parametri di lancio, i file si trovano al percorso specificato nella \Cref{sec:preparation}.

  \paragraph{File/Tabelle di Output}\label{par:job1:mapreduce:output}

  Viene generato un output per ogni passo di MapReduce che viene concluso;
  se non si effettua override dei percorsi tramite parametri di lancio, i file si trovano al percorso specificato nella \Cref{sec:preparation}.

  L'output finale è composto da un singolo file nella cartella output contenente, per ogni linea, un tag separato con un tab da proporzione e numero di apparizioni separate da virgola.

  Qualora il tag appaia solo in giorni feriali, la proporzione avrà valore \texttt{0.0}, mentre se appare solo in giorni festivi, essa ha valore \texttt{Infinity}.

  \paragraph{Descrizione dell'implementazione}\label{par:job1:mapreduce:implementation}

  Il job è stato realizzato con tre passi di MapReduce.
  Il primo passo prevede il caricamento di entrambi i file:
  \begin{itemize}
    \item
      nella fase di Map, il file contenente i tag viene caricato direttamente senza manipolazione delle informazioni caricate,
      mentre il secondo file è mappato su una coppia \textit{key-value} avente come chiave l'ID della domanda
      e come valore un booleano che è \texttt{true} qualora la data di creazione sia un giorno feriale, o altrimenti \texttt{false}.
    \item
      nella fase di Reduce, viene effettuato il \textit{join} tra le informazioni caricate dai due file sulla base dell'ID della domanda,
      in modo da avere in output coppie \textit{key-value} aventi come chiave il tag e come valore il booleano di cui sopra.
  \end{itemize}

  Nel secondo passo, invece, si occupa di effettuare i calcoli richiesti per l'analisi:
  \begin{itemize}
    \item
      nella fase di Map, l'output del passo precedente viene caricato, senza manipolazioni particolari;
      è infatti sufficiente l'aggregazione per chiave (il tag) effettuata dal \textbf{TODO} in ingresso al Reducer.

    \item
      nella fase di Reduce, per ciascun tag vengono mantenuti due contatori per le apparizioni in giorni feriali e festivi,
      in modo da poter generare in output delle coppie \textit{key-value} aventi come chiave il singolo tag e come valore la proporzione tra giorni feriali e festivi e il totale delle apparizioni del tag.
  \end{itemize}

  Il terzo passo costituisce infine il passo di ordinamento secondo le specifiche; per effettuare l'ordinamento, si è realizzato una classe specifica
  \begin{itemize}
    \item
      nella fase di Map, le coppie chiave-valore ottenute dall'output al passo precedente sono invertite, in modo da poter aggregare per proporzione e contatore;
      inoltre, per poter garantire un ordine per quanto riguarda proporzione, contatore, e, in caso di parità, anche alfabetico per tag,
      per l'implementazione pratica, si è realizzato una classe specifica per la chiave composita (\texttt{TextTriplet}) e dei comparatori dedicati per l'ordinamento e il raggruppamento.

    \item
      nella fase di Reduce, la chiave composita viene rimossa e si inverte nuovamente chiave e valore, avendo così coppie tag e valori ordinati per valore;
      per garantire un singolo file di output ordinato, si utilizza un singolo task di reduce.
  \end{itemize}

  I job leggono e producono dati formattati secondo il paradigma chiave-valore utilizzando come formato la classe \texttt{Text} tranne per quanto riguarda l'output del Map nel job di ordinamento.

  \paragraph{Considerazioni sulle performance}\label{par:job1:mapreduce:performance}

  \textbf{TODO}

  \subsubsection{Spark SQL implementation}\label{subsub:job1:spark}

  \paragraph{Comando per eseguire il Job}\label{par:job1:spark:cmd}

  \texttt{spark2-submit bd-stacklite-jobs-1.0.0-spark.jar JOB1}

  La classe \texttt{ScalaMain} è stata costruita in modo tale da permettere all'utente di eseguire tutti i Job implementati tramite
  Spark SQL attraverso un unico jar, avendo la possibilità di specificare, tramite parametro, il Job specifico da lanciare.
  I differenti Job sono definiti dai seguenti parametri:
  \begin{itemize}
    \item JOB1
    \item JOB2
    \item JOBML
  \end{itemize}

  Il comando di lancio del Jar accetta, inoltre altri tre parametri, che permettono di settare le seguenti configurazioni di Spark SQL\@:
  \begin{itemize}
    \item \texttt{spark.default.parallelism}: di default settato a 8, è il secondo parametro (dopo la specificazione del Job).
    \item \texttt{spark.sql.shuffle.partitions}: di default settato a 8, è il terzo parametro.
    \item \texttt{spark.executor.memory}: di default settato a 11, è il quarto parametro.
  \end{itemize}

  Infine, è possibile utilizzare tutti i parametri standard ammessi dall'operazione submit di Spark\footnote{\url{https://spark.apache.org/docs/2.1.0/submitting-applications.html}},
  in quando la configurazione della SparkSession è solamente estesa.

  \paragraph{Link all'esecuzione su YARN}\label{par:job1:spark:yarn}

  \textbf{TODO}

  \paragraph{File/Tabelle di Input}\label{par:job1:spark:input}

  Le colonne necessarie al raggiungimento dell'obiettivo dell'analisi sono \texttt{Id} e \texttt{CreationDate} per il file \texttt{questions.csv}
  e \texttt{Id} e \texttt{Tag} per \texttt{question\_tags.csv}.

  I due file si trovano al percorso specificato nella \Cref{sec:preparation}.

  \paragraph{File/Tabelle di Output}\label{par:job1:spark:output}

  Il Job genera un DataFrame di output, che viene salvato come tabella (nominata \texttt{FinalTableJob1})
  sulla piattaforma Hive all'interno del database \texttt{lsemprini\_nmaltoni\_stacklite\_db}.

  \paragraph{Descrizione dell'implementazione}\label{par:job1:spark:implementation}

  \textbf{TODO}

  \paragraph{Considerazioni sulle performance}\label{par:job1:spark:performance}

  \textbf{TODO}
