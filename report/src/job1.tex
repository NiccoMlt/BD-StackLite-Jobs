%% Direttive TeXworks:
% !TeX root = ../report.tex
% !TEX encoding = UTF-8 Unicode
% !TeX spellcheck = it-IT

% arara: pdflatex: { synctex: yes, shell: yes, interaction: nonstopmode }
% arara: pdflatex: { synctex: yes, shell: yes, interaction: nonstopmode }

\subsection{Job 1: Proporzione giorni feriali/festivi per tag}\label{subsec:job1}
  Il job concordato consiste nel calcolo, per ciascun tag, della proporzione tra la quantità di post che lo utilizzano creati in giorni feriali e giorni festivi, tenendo traccia della quantità totale ai fini dell'ordinamento.

  Durante la fase di studio del dataset, è risultato subito evidente l'esigenza di utilizzare entrambi i file, effettuando un \textit{join} per ID della domanda in modo da poter mettere in relazioni i singoli tag con le informazioni relative ai giorni di apparizione;
  il passo logico successivo è il raggruppamento per tag ai fini del calcolo del numero di apparizioni e della proporzione.

  Si è inoltre ritenuto non necessario mantenere la data di creazione come stringa nella pipeline, in quanto più che sufficiente un booleano che modellasse la festività o meno del giorno di creazione;
  per verificare se un giorno è festivo o meno si è deciso di appoggiarsi alla libreria \textit{Jollyday}\footnote{\url{http://jollyday.sourceforge.net/}} utilizzando il calendario italiano come riferimento per le festività.

  \subsubsection{MapReduce implementation}\label{subsub:job1:mapreduce}

  \paragraph{Comando per eseguire il Job}\label{par:job1:mapreduce:cmd}

  \texttt{hadoop jar bd-stacklite-jobs-1.0.0-mr1.jar}

  Essendo la classe \textit{main} eseguita tramite \texttt{ToolRunner} di Hadoop, supporta il parsing di parametri standard\footnote{\url{https://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-common/CommandsManual.html}} quali ad esempio:
  \begin{itemize}
    \item \texttt{-conf} per caricare una configurazione esterna;
    \item \texttt{-D} per specificare proprietà specifiche per la configurazione;
    \item \texttt{-h} o \texttt{--help} per stampare le opzioni accettate.
  \end{itemize}

  Inoltre, è possibile specificare come primo parametro il path della cartella in ingresso e come secondo paramtero quello della cartella in uscita.

  \paragraph{Link all'esecuzione su YARN}\label{par:job1:mapreduce:yarn}

  \textbf{TODO}

  \paragraph{File/Tabelle di Input}\label{par:job1:mapreduce:input}

  Le colonne necessarie al raggiungimento dell'obiettivo dell'analisi sono \texttt{Id} e \texttt{CreationDate} per il file \texttt{questions.csv}
  e \texttt{Id} e \texttt{Tag} per \texttt{question\_tags.csv}.

  Se non si effettua override dei percorsi tramite parametri di lancio, i file si trovano al percorso specificato nella \Cref{sec:preparation}.

  \paragraph{File/Tabelle di Output}\label{par:job1:mapreduce:output}

  Viene generato un output per ogni passo di MapReduce che viene concluso;
  se non si effettua override dei percorsi tramite parametri di lancio, i file si trovano al percorso specificato nella \Cref{sec:preparation}.

  \textbf{TODO}

  L'output finale è nella forma: \textbf{TODO}

  \paragraph{Descrizione dell'implementazione}\label{par:job1:mapreduce:implementation}

  TODO

  \paragraph{Considerazioni sulle performance}\label{par:job1:mapreduce:performance}

  TODO

  \subsubsection{Spark SQL implementation}\label{subsub:job1:spark}

  \paragraph{Comando per eseguire il Job}\label{par:job1:spark:cmd}

  \texttt{spark2-submit bd-stacklite-jobs-1.0.0-spark.jar JOB1}

  La classe \texttt{ScalaMain} è stata costruita in modo tale da permettere all'utente di eseguire tutti i Job implementati tramite
  Spark SQL attraverso un unico jar, avendo la possibilità di specificare, tramite parametro, il Job specifico da lanciare.
  I differenti Job sono definiti dai seguenti parametri:
  \begin{itemize}
    \item JOB1
    \item JOB2
    \item JOBML
  \end{itemize}

  Il comando di lancio del Jar accetta, inoltre altri tre parametri, che permettono di settare le seguenti configurazioni di Spark SQL:
  \begin{itemize}
    \item \texttt{spark.default.parallelism} : di default settato a 8, è il secondo parametro (dopo la specificazione del Job).
    \item \texttt{spark.sql.shuffle.partitions} : di default settato a 8, è il terzo parametro.
    \item \texttt{spark.executor.memory} : di default settato a 11, è il quarto parametro.
  \item \end{itemize}

\paragraph{Link all'esecuzione su YARN}\label{par:job1:spark:yarn}

  TODO

\paragraph{File/Tabelle di Input}\label{par:job1:spark:input}

  Le colonne necessarie al raggiungimento dell'obiettivo dell'analisi sono \texttt{Id} e \texttt{CreationDate} per il file \texttt{questions.csv}
  e \texttt{Id} e \texttt{Tag} per \texttt{question\_tags.csv}.

  I due file si trovano al percorso specificato nella \Cref{sec:preparation}.

\paragraph{File/Tabelle di Output}\label{par:job1:spark:output}

  Il Job genera un Data Frame di output, che viene salvato come tabella (nominata \texttt{FinalTableJob1})
  sulla piattaforma Hive all'interno del database \texttt{lsemprini_nmaltoni_stacklite_db}.

\paragraph{Descrizione dell'implementazione}\label{par:job1:spark:implementation}

  TODO

  \paragraph{Considerazioni sulle performance}\label{par:job1:spark:performance}

  TODO
