%% Direttive TeXworks:
% !TeX root = ../report.tex
% !TEX encoding = UTF-8 Unicode
% !TeX spellcheck = it-IT

% arara: pdflatex: { synctex: yes, shell: yes, interaction: nonstopmode }
% arara: pdflatex: { synctex: yes, shell: yes, interaction: nonstopmode }

\subsection[%
    Job 3: Correlazione tra punteggio e risposte%
  ]{%
    Job 3: Correlazione tra punteggio e risposte tramite Machine Learning%
  }\label{subsec:job3}

  Il terzo e ultimo job concordato richiede l'utilizzo della libreria MLlib di Spark per il calcolo del coefficiente di correlazione
  tra punteggio e numero di risposte utilizzando tecniche di Machine Learning, ignorando le domande cancellate.

  I coefficienti di correlazione supportati da Spark sono il \textit{coefficiente di correlazione lineare di \textbf{Pearson}} e il \textit{coefficiente di correlazione per ranghi di \textbf{Spearman}}.

  Analizzando il dataset, appare chiaro come sia sufficiente caricare solamente il file contenente le domande, in quanto le informazioni relative ai tag non sono necessarie.

  \paragraph{Comando per eseguire il Job}\label{par:job3:cmd}

  \texttt{spark2-submit bd-stacklite-jobs-1.0.0-spark.jar JOBML}

  La classe \texttt{ScalaMain} è stata costruita in modo tale da permettere all'utente di eseguire tutti i Job implementati tramite
  Spark SQL attraverso un unico jar, avendo la possibilità di specificare, tramite parametro, il Job specifico da lanciare.

  Il comando di lancio del Jar accetta inoltre altri tre parametri, che permettono di settare le seguenti configurazioni di Spark\@:
  \begin{itemize}
    \item \texttt{spark.default.parallelism}: di default settato a 8, è il secondo parametro (dopo la specificazione del Job).
    \item \texttt{spark.sql.shuffle.partitions}: di default settato a 8, è il terzo parametro.
    \item \texttt{spark.executor.memory}: di default settato a 5, è il quarto parametro.
  \end{itemize}

  Infine, è possibile utilizzare tutti i parametri standard ammessi dall'operazione submit di Spark\footnote{\url{https://spark.apache.org/docs/2.1.0/submitting-applications.html}},
  in quando la configurazione della SparkSession è solamente estesa.

  \paragraph{Link all'esecuzione su YARN}\label{par:job3:yarn}

  \textbf{TODO}

  \paragraph{File/Tabelle di Input}\label{par:job3:input}

  Le colonne necessarie al raggiungimento dell'obiettivo dell'analisi sono \texttt{Score} ed \texttt{AnswerCount} per il file \texttt{questions.csv};
  durante l'elaborazione, è necessario mantenere anche la colonna \texttt{DeletionDate} per poter ignorare le risposte cancellate

  \paragraph{File/Tabelle di Output}\label{par:job3:output}

  Viene generato un singolo file di testo nella cartella output contenente due linee recanti il nome dell'algoritmo e il relativo valore calcolato contenuti tra parentesi e separati da virgola.

  \paragraph{Descrizione dell'implementazione}\label{par:job3:implementation}

  La libreria MLlib fornita nel classpath sul server è aggiornata alla versione 2.1.0 e non supporta le Correlation API del package \texttt{org.apache.spark.ml} (il cui supporto è stato introdotto solo dalla versione 2.2.0);
  di conseguenza, si è deciso di utilizzare le Statistics API fornite nel package \texttt{org.apache.spark.mllib}, per quanto consci che sia in via di deprecazione nelle versioni successive.

  \begin{itemize}
    \item
      \textbf{Creazione DataFrame}:
      Come passo iniziale, si è creato il DataFrame caricando il file \texttt{questions.csv} utilizzando la
      classe \texttt{DFBuilder}, che si occupa anche di ricavare lo schema tramite la prima riga e costruire una tabella temporanea.

    \item
      \textbf{Taglio delle colonne non necessarie e rimozione dei valori non validi}:
      Inizialmente, si è proceduto a selezionare le colonne \texttt{DeletionDate}, \texttt{Score} ed \texttt{AnswerCount}, salvando il risultato in un DataFrame.
      Una volta pulito il DataFrame da ogni entry che presentasse un valore differente da ``\texttt{NA}'' come data di eliminazione tramite un'operazione di filtro,
      si è proceduto al drop anche della colonna \texttt{DeletionDate}.

      Successivamente, si è provveduto a rimuovere anche le entry con numero di risposte ``\texttt{NA}'' o negativo.

    \item
      \textbf{Suddivisione del DataFrame in RDD colonna}:
      Per poter effettuare il calcolo della correlazione, si è proceduto a suddividere il DataFrame in due RDD ciascuno riportante i dati da una delle due colonne;
      per fare ciò, è stato sufficiente selezionare la colonna e mappare la stringa contenuta in ciascuna \texttt{Row} in un valore \texttt{Double}.

    \item
      \textbf{Calcolo dei coefficienti e salvataggio dei risultati}:
      Il calcolo dei coefficienti è immediato tramite metodo \texttt{corr} fornito dalla classe \texttt{Statistics};
      una volta ottenuti entrambi i valori, viene costruito un RDD a partire da una sequenza di tuple
      aventi come chiave il nome dell'algoritmo e come valore il rispettivo coefficiente ricavato nei passi precedenti
      e viene scritto su filesystem HDFS in formato testuale.
  \end{itemize}

  \paragraph{Considerazioni sulle performance}\label{par:job3:performance}

  Nonostante la necessità di impiegare il costrutto RDD per il calcolo dei coefficienti di correlazione con le API fornite,
  si è deciso di utilizzare le API pensate per i DataFrame per il caricamento del file CSV e la manipolazione dei dati in esso contenuti
  in quanto maggiormente ottimizzata per questo specifico formato:
  utilizzando infatti il metodo \texttt{.read.csv()} fornito dall'\texttt{SQLContext}, utilizzando la prima riga come header e evitando l'inferenza automatica della struttura, senza creare una tabella temporanea, % chktex 36
  si è ottenuto un guadagno di circa 1 minuto.

  L'impiego di tecniche di \textit{caching} è stato difficoltoso in quanto con 1GB di memoria fornita il job falliva per saturazione dell'\textit{heap}.
  Inizialmente avevamo optato per evitare l'impiego di caching e i tempi si aggiravano intorno ai 9 minuti.

  Aumentando la memoria disponibile a 5GB è invece possibile utilizzare la persistenza degli RDD relativi ai due assi da correlare, ottenendo un guadagno di un terzo in termini di minuti:
  si è passati infatti da circa 9 minuti a circa 6 minuti.

  \paragraph{Considerazioni sull'output finale}

  I risultati ottenuti sono i seguenti:

  \begin{description}[itemsep=1pt]
    \item[\textit{Coefficiente di \textbf{Pearson}}] 0.297397690528351
    \item[\textit{Coefficiente di \textbf{Spearman}}] 0.23110551110424213
  \end{description}

  Come è possibile vedere, i coefficienti mostrano una bassa correlazione, sia lineare che non, tra i numero di risposte e punteggio.
