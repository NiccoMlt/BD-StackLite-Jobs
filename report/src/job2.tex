%% Direttive TeXworks:
% !TeX root = ../report.tex
% !TEX encoding = UTF-8 Unicode
% !TeX spellcheck = it-IT

% arara: pdflatex: { synctex: yes, shell: yes, interaction: nonstopmode }
% arara: pdflatex: { synctex: yes, shell: yes, interaction: nonstopmode }

\subsection[%
    Job 2: Suddividere tag in base a score e risposte%
  ]{%
    Job 2: Suddividere i tag in 4 bin per score e risposte e ottenere i top 10 per ciascun bin%
  }\label{subsec:job2}

  Il secondo job concordato consiste nella suddivisione dei tag in 4 sulla base dei valori di score e numero di risposte:

  \begin{itemize}
    \item score basso, numero di risposte basso
    \item score basso, numero di risposte alto
    \item score alto, numero di risposte basso
    \item score alto, numero di risposte alto
  \end{itemize}

  Per ogni bin è richiesto visualizzare la lista dei primi 10 tag per numero di apparizioni.

  Durante la fase di studio del dataset, è risultato subito evidente l'esigenza di utilizzare entrambi i file,
  effettuando un \textit{join} per ID della domanda in modo da poter mettere in relazioni i singoli tag con punteggio e numero di risposte.

  Una volta messo in relazione ciascuna apparizione di ogni tag con il punteggio e il numero di risposte ottenuto (che permettono la scelta del bin di appartenenza),
  è sufficiente raggruppare per tag e per bin per poter effettuare un conteggio.

  Infine, raggruppando unicamente per bin è possibile ottenere una lista di tag con relativo numero di apparizioni.

  \subsubsection{MapReduce implementation}\label{subsub:job2:mapreduce}

  \paragraph{Comando per eseguire il Job}\label{par:job2:mapreduce:cmd}

  \texttt{hadoop jar bd-stacklite-jobs-1.0.0-mr2.jar}

  I parametri supportati sono i medesimi descritti nella \Cref{par:job1:mapreduce:cmd} relativamente al JAR di MapReduce del job 1.

  \paragraph{Link all'esecuzione su YARN}\label{par:job2:mapreduce:yarn}

  \textbf{TODO}

  \paragraph{File/Tabelle di Input}\label{par:job2:mapreduce:input}

  Le colonne necessarie per l'analisi sono \texttt{Id}, \texttt{Score} e \texttt{AnswerCount} per il file \texttt{questions.csv}
  e \texttt{Id} e \texttt{Tag} per \texttt{question\_tags.csv}.

  Se non si effettua override dei percorsi tramite parametri di lancio, i file si trovano al percorso specificato nella \Cref{sec:preparation}.

  \paragraph{File/Tabelle di Output}\label{par:job2:mapreduce:output}

  Viene generato un output per ogni passo di MapReduce che viene concluso;
  se non si effettua override dei percorsi tramite parametri di lancio, i file si trovano al percorso specificato nella \Cref{sec:preparation}.

  L'output finale è composto da 4 file nella cartella di output, ciascuno contenente i top 10 tag per numero di apparizioni in quel bin;
  ciascuna riga del file contiene il nome del bin separata con un tab dal nome del tag e il relativo contatore, separati tra loro da virgola.

  \paragraph{Descrizione dell'implementazione}\label{par:job2:mapreduce:implementation}

  Anche questo job è realizzato con tre passi di MapReduce.
  Il \textbf{primo passo} prevede il caricamento di entrambi i file:
  \begin{itemize}
    \item
    \textbf{Fase di Map}:
      il file contenente i tag viene caricato direttamente senza manipolazione delle informazioni caricate,
      mentre il secondo file è mappato su una coppia \textit{key-value} avente come chiave l'ID della domanda
      e come valore una coppia contenente il punteggio e il numero di risposte.

    \item
      \textbf{Fase di Reduce}:
      viene effettuato il \textit{join} tra le informazioni caricate dai due file sulla base dell'ID della domanda,
      in modo da avere in output coppie \textit{key-value} aventi come chiave il tag e come valore la coppia di cui sopra.
  \end{itemize}

  Il \textbf{secondo passo} ci si occupa di effettuare i calcoli richiesti per l'analisi:
  \begin{itemize}
    \item
      \textbf{Fase di Map}:
      l'output del passo precedente viene caricato mappando la coppia costituita da punteggio e numero di risposte in uno dei 4 bin;
      in uscita al job, vengono prodotte coppie \textit{key-value} aventi come chiave la coppia di tag e bin e come valore un long di valore 1.

      Per ottimizzare la fase di conto presente nella successiva Reduce, si è aggiunto un \textbf{Combiner} in uscita al Mapper che esegue le medesime operazioni
      descritte nel punto seguente dal Reducer.
    \item
      \textbf{Fase di Reduce}:
      in questa fase viene eseguito un semplice \textit{count} delle apparizioni di ciascun tag in ciascun bin.

      In output a questa fase sono prodotte coppie \textit{key-value} aventi come chiave la coppia di tag e bin e come valore il contatore.
  \end{itemize}

  Infine, nel \textbf{terzo passo}, i dati vengono raccolti e ordinati:
  \begin{itemize}
    \item
      \textbf{Fase di Map}:
      le coppie chiave-valore in output alla fase precedente vengono manipolate
      al fine di generare, per ciascuna, nuove coppie aventi come chiave il bin e come valore la coppia di tag e numero di apparizioni.
    \item
      \textbf{Fase di Reduce}:
      per ciascun bin le coppie in uscita dalla fase di Map vengono raccolte in una mappa;
      in questo modo, al termine della riduzione, la lista di \textit{entry} della mappa viene ordinata e vengono emesse in output le prime 10 entry per ogni bin.
  \end{itemize}

  \paragraph{Considerazioni sulle performance}\label{par:job2:mapreduce:performance}

  Il job impiega circa 4 minuti per eseguire completamente.

  L'operazione di ottimizzazione principale da noi applicata è l'inserimento di un Combiner in uscita ai Mapper al secondo passo,
  che ci ha permesso di ridurre il tempo di esecuzione a quello attuale.

  \subsubsection{Spark SQL implementation}\label{subsub:job2:spark}

  \paragraph{Comando per eseguire il Job}\label{par:job2:spark:cmd}

  \texttt{spark2-submit bd-stacklite-jobs-1.0.0-spark.jar JOB2}

  I parametri supportati sono i medesimi descritti nella \Cref{par:job1:spark:cmd} relativamente al JAR di Spark del job 1.

  \paragraph{Link all'esecuzione su YARN}\label{par:job2:spark:yarn}

  \textbf{TODO}

  \paragraph{File/Tabelle di Input}\label{par:job2:spark:input}

  Le colonne necessarie al raggiungimento dell'obiettivo dell'analisi sono \texttt{Id} e \texttt{Tag} per il file \texttt{question\_tags.csv}
  e \texttt{Id}, \texttt{Score} ed \texttt{AnswerCount} per il file \texttt{questions.csv}.

  \paragraph{File/Tabelle di Output}\label{par:job2:spark:output}

  \textbf{TODO: cambiare nome del DB}

  Il Job genera un DataFrame di output, che viene salvato come tabella (nominata \texttt{FinalTableJob1})
  sulla piattaforma Hive all'interno del database \texttt{lsemprini\_nmaltoni\_stacklite\_db}.

  \paragraph{Descrizione dell'implementazione}\label{par:job2:spark:implementation}

  L'implementazione del Job è stata realizzata utilizzando SparkSQL, contenuta all'interno del metodo \texttt{executeJob()}
  della classe \texttt{it.unibo.bd1819.daysproportion.Job2Main}.
  Il problema è stato affrontato attraverso diversi steps successivi, descritti di seguito:

  \begin{itemize}
    \item \textbf{Creazione DataFrame} : Il passo iniziale è equivalente a quello del Job1
    (\Cref{par:job1:spark:implementation:firststep}).
    \item \textbf{Taglio delle colonne non necessarie} : Si è proceduto ad selezionare unicamente le colonne \texttt{Id},
    \texttt{Score} ed \texttt{AnswerCount} per il Data Frame \texttt{questions}, salvando il risultato in un Data Frame,
    a sua volta salvato in cache, in quanto necessario per l'operazione successiva.
    \item \textbf{Join con \texttt{question\_tags}, Filter e Mapping} : Il terzo step è composto a sua volta da sotto-step:
    \begin{itemize}
      \item Join : Si effettua il Join del Data Frame ottenuto dal secondo step con il Data Frame \texttt{question\_tags}, attraverso
      la colonna \texttt{Id}, per poi effettuare il drop della stessa, in quanto superflua per le operazioni successive.
      \item Filtraggio : A questo punto vengono selezionate le colonne \texttt{Tag}, \texttt{Score} ed \texttt{AnswerCount}
      e viene effettuata una operazione di \texttt{filter} su eventuali valori delle colonne \texttt{Score} ed \texttt{AnswerCount}
      che andrebbero ad inficiare l'analisi, ovvero, si filtrano le righe contenenti \texttt{Score} ed \texttt{AnswerCount} con valore
      "NA".
      \item Mapping : Infine, mantenendo ovviamente la colonna \texttt{Tag},
      si mappano i valori di \texttt{Score} ed \texttt{AnswerCount}, utilizzandoli come input di una funzione
      \texttt{getBinFor()} della classe \texttt{Bin}, che, presi i valori di \texttt{Score} ed \texttt{AnswerCount} ed le relative
      soglie arbitrarie, restituisce una stringa che esprimerà a quale Bin apparterrà ogni occorrenza di \texttt{Tag}.
    \end{itemize}
    Il Data Frame risultante viene salvato come tabella temporanea con il nome \texttt{binDF}.
    \item \textbf{Conteggio e ordinamento} : L'informazione contenuta nel Data Frame \texttt{binDF} viene arricchita dall'aggiunta
    della colonna \texttt{Count} che rappresenterà il numero di occorrenze delle coppie (\texttt{Tag}, \texttt{Bin}) presenti
    nel Data Frame; il tutto viene quindi ordinato per \texttt{Bin} e \texttt{Count} in ordine decrescente, per facilitare lo step
    successivo.
    Per effettuare l'operazione è stata dunque utilizzata la seguente query:
    \texttt{SELECT Tag, Bin, COUNT(*) AS Count FROM binDF GROUP BY Tag, Bin ORDER BY Bin, Count DESC}

    Il Data Frame ottenuto viene salvato come tabella temporanea con il nome di \texttt{binCountDF}.
    \item \textbf{Ottenimento delle liste per ogni Bin} : In questo ultimo step è stata eseguita una query sul Data Frame
    \texttt{binCountDF} che permette, per ognuno dei quattro Bin di ottenere una lista delle prime dieci coppie
    (\texttt{Tag}, \texttt{Count}) ordinate per \texttt{Count}.
    Nella query viene utilizzata la funzione \texttt{COLLECT\_LIST}, combinata con la funzione \texttt{CONCAT} per accorpare
    le due colonne \texttt{Tag} e \texttt{Count} all'interno di una lista.
    La query usata è la seguente:
    \texttt{SELECT Bin, COLLECT\_LIST(CONCAT(Tag,' - ',Count)) AS ListTagCount FROM binCountDF GROUP BY Bin}

    A questo punto ottengo un Data Frame in cui si va a mappare la seconda colonna (\texttt{ListTagCount}) in modo da ottenere
    solo le prime dieci coppie (\texttt{Tag}, \texttt{Count}), che sono già state ordinate nello step precedente.

    Il Data Frame ottenuto sarà il risultato finale del Job e viene salvato come tabella su Hive tramite il metodo
    \texttt{saveAsTable()}.
  \end{itemize}


  \paragraph{Considerazioni sulle performance}\label{par:job2:spark:performance}

  Il Job implementato in Spark SQL impiega circa 5 minuti e mezzo per essere portato a compimento.
  Tempo di esecuzione che è stato pressoché dimezzato da alcuni accorgimenti apportati durante la fase di ottimizzazione.
  Evitare di salvare in cache eccessivamente i Data Frame ottenuti dalle varie operazioni ha aiutato molto a migliorare
  le performance complessive.
  Un altra intuizione è stata quella di accorpare le operazioni descritte nel terzo step in un'unica query, quando inizialmente
  veniva eseguito a parte il Join dei due Data Frame, cosa che, è stato riscontrato, andava ad aumentare il tempo di esecuzione,
  in quanto veniva salvata una ulteriore tabella temporanea.
  L'operazione di \texttt{filter} sui valori "NA" di \texttt{Score} ed \texttt{AnswerCount} è stata, inoltre, spostata al di fuori
  dalla successiva operazione di \texttt{map}, in quanto si è riscontrato fosse nettamente più conveniente dal punto di vista
  delle performance stesse: così facendo si va ad alleggerire la tabella, e meno righe verranno computate dalla \texttt{map}.

