%% Direttive TeXworks:
% !TeX root = ../report.tex
% !TEX encoding = UTF-8 Unicode
% !TeX spellcheck = it-IT

% arara: pdflatex: { synctex: yes, shell: yes, interaction: nonstopmode }
% arara: pdflatex: { synctex: yes, shell: yes, interaction: nonstopmode }

\subsection[%
    Job 2: Suddividere tag in base a score e risposte%
  ]{%
    Job 2: Suddividere i tag in 4 bin per score e risposte e ottenere i top 10 per ciascun bin%
  }\label{subsec:job2}

  Il secondo job concordato consiste nella suddivisione dei tag in 4 sulla base dei valori di score e numero di risposte:

  \begin{itemize}
    \item score basso, numero di risposte basso
    \item score basso, numero di risposte alto
    \item score alto, numero di risposte basso
    \item score alto, numero di risposte alto
  \end{itemize}

  Per ogni bin è richiesto visualizzare la lista dei primi 10 tag per numero di apparizioni.

  Durante la fase di studio del dataset, è risultato subito evidente l'esigenza di utilizzare entrambi i file,
  effettuando un \textit{join} per ID della domanda in modo da poter mettere in relazioni i singoli tag con punteggio e numero di risposte.

  Una volta messo in relazione ciascuna apparizione di ogni tag con il punteggio e il numero di risposte ottenuto (che permettono la scelta del bin di appartenenza),
  è sufficiente raggruppare per tag e per bin per poter effettuare un conteggio.

  Infine, raggruppando unicamente per bin è possibile ottenere una lista di tag con relativo numero di apparizioni.

  \subsubsection{MapReduce implementation}\label{subsub:job2:mapreduce}

  \paragraph{Comando per eseguire il Job}\label{par:job2:mapreduce:cmd}

  \texttt{hadoop jar bd-stacklite-jobs-1.0.0-mr2.jar}

  Essendo la classe \textit{main} eseguita tramite \texttt{ToolRunner} di Hadoop,
  supporta il parsing di parametri standard di Hadoop\footnote{\url{https://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-common/CommandsManual.html}}, quali ad esempio:
  \begin{itemize}
    \item \texttt{-conf} per caricare una configurazione esterna;
    \item \texttt{-D} per specificare proprietà specifiche per la configurazione;
    \item \texttt{-h} o \texttt{--help} per stampare le opzioni accettate.
  \end{itemize}

  Inoltre, è possibile specificare come primo parametro il path della cartella in ingresso e come secondo paramtero quello della cartella in uscita.

  \paragraph{Link all'esecuzione su YARN}\label{par:job2:mapreduce:yarn}

  \textbf{TODO}

  \paragraph{File/Tabelle di Input}\label{par:job2:mapreduce:input}

  Le colonne necessarie per l'analisi sono \texttt{Id}, \texttt{Score} e \texttt{AnswerCount} per il file \texttt{questions.csv}
  e \texttt{Id} e \texttt{Tag} per \texttt{question\_tags.csv}.

  Se non si effettua override dei percorsi tramite parametri di lancio, i file si trovano al percorso specificato nella \Cref{sec:preparation}.

  \paragraph{File/Tabelle di Output}\label{par:job2:mapreduce:output}

  Viene generato un output per ogni passo di MapReduce che viene concluso;
  se non si effettua override dei percorsi tramite parametri di lancio, i file si trovano al percorso specificato nella \Cref{sec:preparation}.

  L'output finale è composto da un singolo file nella cartella output contenente, \textbf{TODO}

  \textbf{TODO}

  \paragraph{Descrizione dell'implementazione}\label{par:job2:mapreduce:implementation}

  \textbf{TODO}

  \paragraph{Considerazioni sulle performance}\label{par:job2:mapreduce:performance}

  \textbf{TODO}

  \subsubsection{Spark SQL implementation}\label{subsub:job2:spark}

  \paragraph{Comando per eseguire il Job}\label{par:job2:spark:cmd}

  \textbf{TODO}

  \paragraph{Link all'esecuzione su YARN}\label{par:job2:spark:yarn}

  \textbf{TODO}

  \paragraph{File/Tabelle di Input}\label{par:job2:spark:input}

  \textbf{TODO}

  \paragraph{File/Tabelle di Output}\label{par:job2:spark:output}

  \textbf{TODO}

  \paragraph{Descrizione dell'implementazione}\label{par:job2:spark:implementation}

  \textbf{TODO}

  \paragraph{Considerazioni sulle performance}\label{par:job2:spark:performance}

  \textbf{TODO}
